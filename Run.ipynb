{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from linear_cca import linear_cca\n",
    "from torch.utils.data import BatchSampler, SequentialSampler\n",
    "from DeepCCAModels import DeepCCA\n",
    "from main import Solver\n",
    "from utils import load_data, svm_classify\n",
    "try:\n",
    "    import cPickle as thepickle\n",
    "except ImportError:\n",
    "    import _pickle as thepickle\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3 GPUs\n",
      "loading data ...\n",
      "loading data ...\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# Parameters Section\n",
    "\n",
    "device = torch.device('cuda')\n",
    "print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "\n",
    "# the path to save the final learned features\n",
    "save_to = './new_features.gz'\n",
    "\n",
    "# the size of the new space learned by the model (number of the new features)\n",
    "outdim_size = 10\n",
    "\n",
    "# size of the input for view 1 and view 2\n",
    "input_shape1 = 784\n",
    "input_shape2 = 784\n",
    "\n",
    "# number of layers with nodes in each one\n",
    "layer_sizes1 = [1024, 1024, 1024, outdim_size]\n",
    "layer_sizes2 = [1024, 1024, 1024, outdim_size]\n",
    "\n",
    "# the parameters for training the network\n",
    "learning_rate = 1e-3\n",
    "epoch_num = 100\n",
    "batch_size = 800\n",
    "\n",
    "# the regularization parameter of the network\n",
    "# seems necessary to avoid the gradient exploding especially when non-saturating activations are used\n",
    "reg_par = 1e-5\n",
    "\n",
    "# specifies if all the singular values should get used to calculate the correlation or just the top outdim_size ones\n",
    "# if one option does not work for a network or dataset, try the other one\n",
    "use_all_singular_values = True\n",
    "\n",
    "# if a linear CCA should get applied on the learned features extracted from the networks\n",
    "# it does not affect the performance on noisy MNIST significantly\n",
    "apply_linear_cca = True\n",
    "\n",
    "# end of parameters section\n",
    "############\n",
    "\n",
    "# Each view is stored in a gzip file separately. They will get downloaded the first time the code gets executed.\n",
    "# Datasets get stored under the datasets folder of user's Keras folder\n",
    "# normally under [Home Folder]/.keras/datasets/\n",
    "data1 = load_data('./noisymnist_view1.gz')\n",
    "data2 = load_data('./noisymnist_view2.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2018-10-02 15:22:02,311 ] - DataParallel(\n",
      "  (module): DeepCCA(\n",
      "    (model1): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "        (3): Linear(in_features=1024, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (model2): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "        (3): Linear(in_features=1024, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[ INFO : 2018-10-02 15:22:02,313 ] - RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    momentum: 0\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "[ INFO : 2018-10-02 15:22:28,592 ] - Epoch 00001: val_loss improved from 0.00000 to -1.81204, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:22:35,184 ] - Epoch 1/100 - time: 32.72 - train_loss: -1.6249 - val_loss: -1.8120\n",
      "\n",
      "[ INFO : 2018-10-02 15:22:57,328 ] - Epoch 00002: val_loss improved from -1.81204 to -1.94497, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:23:04,706 ] - Epoch 2/100 - time: 29.52 - train_loss: -1.7671 - val_loss: -1.9450\n",
      "\n",
      "[ INFO : 2018-10-02 15:23:26,869 ] - Epoch 00003: val_loss improved from -1.94497 to -2.03039, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:23:33,072 ] - Epoch 3/100 - time: 28.36 - train_loss: -1.8467 - val_loss: -2.0304\n",
      "\n",
      "[ INFO : 2018-10-02 15:23:55,398 ] - Epoch 00004: val_loss improved from -2.03039 to -2.12114, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:24:00,586 ] - Epoch 4/100 - time: 27.51 - train_loss: -1.9079 - val_loss: -2.1211\n",
      "\n",
      "[ INFO : 2018-10-02 15:24:22,878 ] - Epoch 00005: val_loss improved from -2.12114 to -2.16447, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:24:30,034 ] - Epoch 5/100 - time: 29.45 - train_loss: -1.9603 - val_loss: -2.1645\n",
      "\n",
      "[ INFO : 2018-10-02 15:24:52,361 ] - Epoch 00006: val_loss improved from -2.16447 to -2.19743, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:24:59,394 ] - Epoch 6/100 - time: 29.36 - train_loss: -2.0052 - val_loss: -2.1974\n",
      "\n",
      "[ INFO : 2018-10-02 15:25:21,662 ] - Epoch 00007: val_loss improved from -2.19743 to -2.21246, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:25:28,256 ] - Epoch 7/100 - time: 28.86 - train_loss: -2.0429 - val_loss: -2.2125\n",
      "\n",
      "[ INFO : 2018-10-02 15:25:50,498 ] - Epoch 00008: val_loss improved from -2.21246 to -2.27771, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:25:55,512 ] - Epoch 8/100 - time: 27.26 - train_loss: -2.0753 - val_loss: -2.2777\n",
      "\n",
      "[ INFO : 2018-10-02 15:26:17,773 ] - Epoch 00009: val_loss improved from -2.27771 to -2.29731, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:26:22,990 ] - Epoch 9/100 - time: 27.48 - train_loss: -2.1048 - val_loss: -2.2973\n",
      "\n",
      "[ INFO : 2018-10-02 15:26:45,228 ] - Epoch 00010: val_loss improved from -2.29731 to -2.34357, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:26:49,809 ] - Epoch 10/100 - time: 26.82 - train_loss: -2.1302 - val_loss: -2.3436\n",
      "\n",
      "[ INFO : 2018-10-02 15:27:12,101 ] - Epoch 00011: val_loss did not improve from -2.34357\n",
      "[ INFO : 2018-10-02 15:27:12,102 ] - Epoch 11/100 - time: 22.29 - train_loss: -2.1540 - val_loss: -2.2870\n",
      "\n",
      "[ INFO : 2018-10-02 15:27:34,401 ] - Epoch 00012: val_loss improved from -2.34357 to -2.35275, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:27:39,380 ] - Epoch 12/100 - time: 27.28 - train_loss: -2.1753 - val_loss: -2.3527\n",
      "\n",
      "[ INFO : 2018-10-02 15:28:01,663 ] - Epoch 00013: val_loss improved from -2.35275 to -2.35871, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:28:07,604 ] - Epoch 13/100 - time: 28.22 - train_loss: -2.1945 - val_loss: -2.3587\n",
      "\n",
      "[ INFO : 2018-10-02 15:28:29,838 ] - Epoch 00014: val_loss improved from -2.35871 to -2.36153, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:28:35,606 ] - Epoch 14/100 - time: 28.00 - train_loss: -2.2131 - val_loss: -2.3615\n",
      "\n",
      "[ INFO : 2018-10-02 15:28:57,814 ] - Epoch 00015: val_loss improved from -2.36153 to -2.42332, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:29:03,760 ] - Epoch 15/100 - time: 28.15 - train_loss: -2.2294 - val_loss: -2.4233\n",
      "\n",
      "[ INFO : 2018-10-02 15:29:26,005 ] - Epoch 00016: val_loss improved from -2.42332 to -2.49288, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:29:31,809 ] - Epoch 16/100 - time: 28.05 - train_loss: -2.2482 - val_loss: -2.4929\n",
      "\n",
      "[ INFO : 2018-10-02 15:29:53,971 ] - Epoch 00017: val_loss did not improve from -2.49288\n",
      "[ INFO : 2018-10-02 15:29:53,972 ] - Epoch 17/100 - time: 22.16 - train_loss: -2.2668 - val_loss: -2.4641\n",
      "\n",
      "[ INFO : 2018-10-02 15:30:16,216 ] - Epoch 00018: val_loss did not improve from -2.49288\n",
      "[ INFO : 2018-10-02 15:30:16,217 ] - Epoch 18/100 - time: 22.24 - train_loss: -2.2850 - val_loss: -2.4715\n",
      "\n",
      "[ INFO : 2018-10-02 15:30:38,415 ] - Epoch 00019: val_loss did not improve from -2.49288\n",
      "[ INFO : 2018-10-02 15:30:38,416 ] - Epoch 19/100 - time: 22.20 - train_loss: -2.3017 - val_loss: -2.4742\n",
      "\n",
      "[ INFO : 2018-10-02 15:31:00,572 ] - Epoch 00020: val_loss did not improve from -2.49288\n",
      "[ INFO : 2018-10-02 15:31:00,574 ] - Epoch 20/100 - time: 22.16 - train_loss: -2.3180 - val_loss: -2.4823\n",
      "\n",
      "[ INFO : 2018-10-02 15:31:22,662 ] - Epoch 00021: val_loss improved from -2.49288 to -2.52304, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:31:28,402 ] - Epoch 21/100 - time: 27.83 - train_loss: -2.3332 - val_loss: -2.5230\n",
      "\n",
      "[ INFO : 2018-10-02 15:31:50,521 ] - Epoch 00022: val_loss did not improve from -2.52304\n",
      "[ INFO : 2018-10-02 15:31:50,523 ] - Epoch 22/100 - time: 22.12 - train_loss: -2.3475 - val_loss: -2.5160\n",
      "\n",
      "[ INFO : 2018-10-02 15:32:12,688 ] - Epoch 00023: val_loss improved from -2.52304 to -2.55650, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:32:17,483 ] - Epoch 23/100 - time: 26.96 - train_loss: -2.3615 - val_loss: -2.5565\n",
      "\n",
      "[ INFO : 2018-10-02 15:32:39,604 ] - Epoch 00024: val_loss improved from -2.55650 to -2.58591, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:32:44,095 ] - Epoch 24/100 - time: 26.61 - train_loss: -2.3747 - val_loss: -2.5859\n",
      "\n",
      "[ INFO : 2018-10-02 15:33:06,247 ] - Epoch 00025: val_loss improved from -2.58591 to -2.59080, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:33:11,821 ] - Epoch 25/100 - time: 27.72 - train_loss: -2.3870 - val_loss: -2.5908\n",
      "\n",
      "[ INFO : 2018-10-02 15:33:33,906 ] - Epoch 00026: val_loss did not improve from -2.59080\n",
      "[ INFO : 2018-10-02 15:33:33,907 ] - Epoch 26/100 - time: 22.09 - train_loss: -2.3989 - val_loss: -2.5860\n",
      "\n",
      "[ INFO : 2018-10-02 15:33:56,040 ] - Epoch 00027: val_loss did not improve from -2.59080\n",
      "[ INFO : 2018-10-02 15:33:56,041 ] - Epoch 27/100 - time: 22.13 - train_loss: -2.4104 - val_loss: -2.5846\n",
      "\n",
      "[ INFO : 2018-10-02 15:34:18,178 ] - Epoch 00028: val_loss improved from -2.59080 to -2.62586, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:34:24,545 ] - Epoch 28/100 - time: 28.50 - train_loss: -2.4214 - val_loss: -2.6259\n",
      "\n",
      "[ INFO : 2018-10-02 15:34:46,698 ] - Epoch 00029: val_loss did not improve from -2.62586\n",
      "[ INFO : 2018-10-02 15:34:46,700 ] - Epoch 29/100 - time: 22.15 - train_loss: -2.4317 - val_loss: -2.5995\n",
      "\n",
      "[ INFO : 2018-10-02 15:35:08,901 ] - Epoch 00030: val_loss did not improve from -2.62586\n",
      "[ INFO : 2018-10-02 15:35:08,902 ] - Epoch 30/100 - time: 22.20 - train_loss: -2.4419 - val_loss: -2.5588\n",
      "\n",
      "[ INFO : 2018-10-02 15:35:31,064 ] - Epoch 00031: val_loss did not improve from -2.62586\n",
      "[ INFO : 2018-10-02 15:35:31,065 ] - Epoch 31/100 - time: 22.16 - train_loss: -2.4514 - val_loss: -2.5973\n",
      "\n",
      "[ INFO : 2018-10-02 15:35:53,231 ] - Epoch 00032: val_loss did not improve from -2.62586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2018-10-02 15:35:53,233 ] - Epoch 32/100 - time: 22.17 - train_loss: -2.4608 - val_loss: -2.5604\n",
      "\n",
      "[ INFO : 2018-10-02 15:36:15,425 ] - Epoch 00033: val_loss did not improve from -2.62586\n",
      "[ INFO : 2018-10-02 15:36:15,426 ] - Epoch 33/100 - time: 22.19 - train_loss: -2.4698 - val_loss: -2.5780\n",
      "\n",
      "[ INFO : 2018-10-02 15:36:37,586 ] - Epoch 00034: val_loss did not improve from -2.62586\n",
      "[ INFO : 2018-10-02 15:36:37,588 ] - Epoch 34/100 - time: 22.16 - train_loss: -2.4786 - val_loss: -2.6214\n",
      "\n",
      "[ INFO : 2018-10-02 15:36:59,762 ] - Epoch 00035: val_loss improved from -2.62586 to -2.66784, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:37:05,173 ] - Epoch 35/100 - time: 27.58 - train_loss: -2.4869 - val_loss: -2.6678\n",
      "\n",
      "[ INFO : 2018-10-02 15:37:27,354 ] - Epoch 00036: val_loss improved from -2.66784 to -2.66889, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:37:32,730 ] - Epoch 36/100 - time: 27.56 - train_loss: -2.4950 - val_loss: -2.6689\n",
      "\n",
      "[ INFO : 2018-10-02 15:37:54,916 ] - Epoch 00037: val_loss did not improve from -2.66889\n",
      "[ INFO : 2018-10-02 15:37:54,917 ] - Epoch 37/100 - time: 22.19 - train_loss: -2.5031 - val_loss: -2.6469\n",
      "\n",
      "[ INFO : 2018-10-02 15:38:17,049 ] - Epoch 00038: val_loss improved from -2.66889 to -2.67792, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:38:25,417 ] - Epoch 38/100 - time: 30.50 - train_loss: -2.5106 - val_loss: -2.6779\n",
      "\n",
      "[ INFO : 2018-10-02 15:38:47,555 ] - Epoch 00039: val_loss did not improve from -2.67792\n",
      "[ INFO : 2018-10-02 15:38:47,556 ] - Epoch 39/100 - time: 22.14 - train_loss: -2.5180 - val_loss: -2.6766\n",
      "\n",
      "[ INFO : 2018-10-02 15:39:09,724 ] - Epoch 00040: val_loss did not improve from -2.67792\n",
      "[ INFO : 2018-10-02 15:39:09,725 ] - Epoch 40/100 - time: 22.17 - train_loss: -2.5252 - val_loss: -2.6607\n",
      "\n",
      "[ INFO : 2018-10-02 15:39:31,914 ] - Epoch 00041: val_loss did not improve from -2.67792\n",
      "[ INFO : 2018-10-02 15:39:31,916 ] - Epoch 41/100 - time: 22.19 - train_loss: -2.5324 - val_loss: -2.6277\n",
      "\n",
      "[ INFO : 2018-10-02 15:39:54,121 ] - Epoch 00042: val_loss did not improve from -2.67792\n",
      "[ INFO : 2018-10-02 15:39:54,123 ] - Epoch 42/100 - time: 22.21 - train_loss: -2.5393 - val_loss: -2.6200\n",
      "\n",
      "[ INFO : 2018-10-02 15:40:16,297 ] - Epoch 00043: val_loss did not improve from -2.67792\n",
      "[ INFO : 2018-10-02 15:40:16,299 ] - Epoch 43/100 - time: 22.18 - train_loss: -2.5460 - val_loss: -2.6142\n",
      "\n",
      "[ INFO : 2018-10-02 15:40:38,488 ] - Epoch 00044: val_loss did not improve from -2.67792\n",
      "[ INFO : 2018-10-02 15:40:38,490 ] - Epoch 44/100 - time: 22.19 - train_loss: -2.5525 - val_loss: -2.6147\n",
      "\n",
      "[ INFO : 2018-10-02 15:41:00,612 ] - Epoch 00045: val_loss did not improve from -2.67792\n",
      "[ INFO : 2018-10-02 15:41:00,613 ] - Epoch 45/100 - time: 22.12 - train_loss: -2.5590 - val_loss: -2.6722\n",
      "\n",
      "[ INFO : 2018-10-02 15:41:22,793 ] - Epoch 00046: val_loss did not improve from -2.67792\n",
      "[ INFO : 2018-10-02 15:41:22,794 ] - Epoch 46/100 - time: 22.18 - train_loss: -2.5653 - val_loss: -2.6484\n",
      "\n",
      "[ INFO : 2018-10-02 15:41:44,929 ] - Epoch 00047: val_loss improved from -2.67792 to -2.68843, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:41:49,899 ] - Epoch 47/100 - time: 27.10 - train_loss: -2.5715 - val_loss: -2.6884\n",
      "\n",
      "[ INFO : 2018-10-02 15:42:12,121 ] - Epoch 00048: val_loss did not improve from -2.68843\n",
      "[ INFO : 2018-10-02 15:42:12,122 ] - Epoch 48/100 - time: 22.22 - train_loss: -2.5778 - val_loss: -2.6455\n",
      "\n",
      "[ INFO : 2018-10-02 15:42:34,331 ] - Epoch 00049: val_loss did not improve from -2.68843\n",
      "[ INFO : 2018-10-02 15:42:34,332 ] - Epoch 49/100 - time: 22.21 - train_loss: -2.5838 - val_loss: -2.6764\n",
      "\n",
      "[ INFO : 2018-10-02 15:42:56,536 ] - Epoch 00050: val_loss did not improve from -2.68843\n",
      "[ INFO : 2018-10-02 15:42:56,537 ] - Epoch 50/100 - time: 22.20 - train_loss: -2.5898 - val_loss: -2.6853\n",
      "\n",
      "[ INFO : 2018-10-02 15:43:18,641 ] - Epoch 00051: val_loss improved from -2.68843 to -2.68918, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:43:27,602 ] - Epoch 51/100 - time: 31.06 - train_loss: -2.5956 - val_loss: -2.6892\n",
      "\n",
      "[ INFO : 2018-10-02 15:43:49,808 ] - Epoch 00052: val_loss did not improve from -2.68918\n",
      "[ INFO : 2018-10-02 15:43:49,809 ] - Epoch 52/100 - time: 22.21 - train_loss: -2.6014 - val_loss: -2.6788\n",
      "\n",
      "[ INFO : 2018-10-02 15:44:11,966 ] - Epoch 00053: val_loss improved from -2.68918 to -2.69032, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:44:18,118 ] - Epoch 53/100 - time: 28.31 - train_loss: -2.6072 - val_loss: -2.6903\n",
      "\n",
      "[ INFO : 2018-10-02 15:44:40,309 ] - Epoch 00054: val_loss improved from -2.69032 to -2.69525, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:44:46,065 ] - Epoch 54/100 - time: 27.95 - train_loss: -2.6126 - val_loss: -2.6953\n",
      "\n",
      "[ INFO : 2018-10-02 15:45:08,279 ] - Epoch 00055: val_loss did not improve from -2.69525\n",
      "[ INFO : 2018-10-02 15:45:08,281 ] - Epoch 55/100 - time: 22.21 - train_loss: -2.6184 - val_loss: -2.6575\n",
      "\n",
      "[ INFO : 2018-10-02 15:45:30,387 ] - Epoch 00056: val_loss did not improve from -2.69525\n",
      "[ INFO : 2018-10-02 15:45:30,388 ] - Epoch 56/100 - time: 22.11 - train_loss: -2.6239 - val_loss: -2.6610\n",
      "\n",
      "[ INFO : 2018-10-02 15:45:52,517 ] - Epoch 00057: val_loss did not improve from -2.69525\n",
      "[ INFO : 2018-10-02 15:45:52,518 ] - Epoch 57/100 - time: 22.13 - train_loss: -2.6293 - val_loss: -2.6485\n",
      "\n",
      "[ INFO : 2018-10-02 15:46:14,759 ] - Epoch 00058: val_loss improved from -2.69525 to -2.70083, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:46:20,345 ] - Epoch 58/100 - time: 27.83 - train_loss: -2.6347 - val_loss: -2.7008\n",
      "\n",
      "[ INFO : 2018-10-02 15:46:42,602 ] - Epoch 00059: val_loss improved from -2.70083 to -2.71261, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:46:48,572 ] - Epoch 59/100 - time: 28.23 - train_loss: -2.6400 - val_loss: -2.7126\n",
      "\n",
      "[ INFO : 2018-10-02 15:47:10,710 ] - Epoch 00060: val_loss did not improve from -2.71261\n",
      "[ INFO : 2018-10-02 15:47:10,712 ] - Epoch 60/100 - time: 22.14 - train_loss: -2.6453 - val_loss: -2.6978\n",
      "\n",
      "[ INFO : 2018-10-02 15:47:32,910 ] - Epoch 00061: val_loss did not improve from -2.71261\n",
      "[ INFO : 2018-10-02 15:47:32,911 ] - Epoch 61/100 - time: 22.20 - train_loss: -2.6503 - val_loss: -2.7061\n",
      "\n",
      "[ INFO : 2018-10-02 15:47:55,118 ] - Epoch 00062: val_loss did not improve from -2.71261\n",
      "[ INFO : 2018-10-02 15:47:55,119 ] - Epoch 62/100 - time: 22.21 - train_loss: -2.6555 - val_loss: -2.6092\n",
      "\n",
      "[ INFO : 2018-10-02 15:48:17,282 ] - Epoch 00063: val_loss did not improve from -2.71261\n",
      "[ INFO : 2018-10-02 15:48:17,284 ] - Epoch 63/100 - time: 22.16 - train_loss: -2.6605 - val_loss: -2.6780\n",
      "\n",
      "[ INFO : 2018-10-02 15:48:39,470 ] - Epoch 00064: val_loss did not improve from -2.71261\n",
      "[ INFO : 2018-10-02 15:48:39,472 ] - Epoch 64/100 - time: 22.19 - train_loss: -2.6652 - val_loss: -2.6551\n",
      "\n",
      "[ INFO : 2018-10-02 15:49:01,668 ] - Epoch 00065: val_loss did not improve from -2.71261\n",
      "[ INFO : 2018-10-02 15:49:01,670 ] - Epoch 65/100 - time: 22.20 - train_loss: -2.6700 - val_loss: -2.6919\n",
      "\n",
      "[ INFO : 2018-10-02 15:49:23,785 ] - Epoch 00066: val_loss did not improve from -2.71261\n",
      "[ INFO : 2018-10-02 15:49:23,787 ] - Epoch 66/100 - time: 22.12 - train_loss: -2.6747 - val_loss: -2.6425\n",
      "\n",
      "[ INFO : 2018-10-02 15:49:45,980 ] - Epoch 00067: val_loss did not improve from -2.71261\n",
      "[ INFO : 2018-10-02 15:49:45,981 ] - Epoch 67/100 - time: 22.19 - train_loss: -2.6793 - val_loss: -2.6923\n",
      "\n",
      "[ INFO : 2018-10-02 15:50:08,201 ] - Epoch 00068: val_loss did not improve from -2.71261\n",
      "[ INFO : 2018-10-02 15:50:08,203 ] - Epoch 68/100 - time: 22.22 - train_loss: -2.6838 - val_loss: -2.6816\n",
      "\n",
      "[ INFO : 2018-10-02 15:50:30,403 ] - Epoch 00069: val_loss did not improve from -2.71261\n",
      "[ INFO : 2018-10-02 15:50:30,404 ] - Epoch 69/100 - time: 22.20 - train_loss: -2.6882 - val_loss: -2.6918\n",
      "\n",
      "[ INFO : 2018-10-02 15:50:52,640 ] - Epoch 00070: val_loss improved from -2.71261 to -2.72127, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:50:57,779 ] - Epoch 70/100 - time: 27.37 - train_loss: -2.6925 - val_loss: -2.7213\n",
      "\n",
      "[ INFO : 2018-10-02 15:51:20,003 ] - Epoch 00071: val_loss did not improve from -2.72127\n",
      "[ INFO : 2018-10-02 15:51:20,004 ] - Epoch 71/100 - time: 22.22 - train_loss: -2.6969 - val_loss: -2.6931\n",
      "\n",
      "[ INFO : 2018-10-02 15:51:42,196 ] - Epoch 00072: val_loss did not improve from -2.72127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2018-10-02 15:51:42,198 ] - Epoch 72/100 - time: 22.19 - train_loss: -2.7010 - val_loss: -2.7129\n",
      "\n",
      "[ INFO : 2018-10-02 15:52:04,377 ] - Epoch 00073: val_loss did not improve from -2.72127\n",
      "[ INFO : 2018-10-02 15:52:04,378 ] - Epoch 73/100 - time: 22.18 - train_loss: -2.7052 - val_loss: -2.7008\n",
      "\n",
      "[ INFO : 2018-10-02 15:52:26,555 ] - Epoch 00074: val_loss did not improve from -2.72127\n",
      "[ INFO : 2018-10-02 15:52:26,556 ] - Epoch 74/100 - time: 22.18 - train_loss: -2.7092 - val_loss: -2.6507\n",
      "\n",
      "[ INFO : 2018-10-02 15:52:48,675 ] - Epoch 00075: val_loss did not improve from -2.72127\n",
      "[ INFO : 2018-10-02 15:52:48,676 ] - Epoch 75/100 - time: 22.12 - train_loss: -2.7130 - val_loss: -2.6971\n",
      "\n",
      "[ INFO : 2018-10-02 15:53:10,789 ] - Epoch 00076: val_loss did not improve from -2.72127\n",
      "[ INFO : 2018-10-02 15:53:10,791 ] - Epoch 76/100 - time: 22.11 - train_loss: -2.7171 - val_loss: -2.6730\n",
      "\n",
      "[ INFO : 2018-10-02 15:53:33,017 ] - Epoch 00077: val_loss did not improve from -2.72127\n",
      "[ INFO : 2018-10-02 15:53:33,018 ] - Epoch 77/100 - time: 22.23 - train_loss: -2.7208 - val_loss: -2.6828\n",
      "\n",
      "[ INFO : 2018-10-02 15:53:55,215 ] - Epoch 00078: val_loss did not improve from -2.72127\n",
      "[ INFO : 2018-10-02 15:53:55,217 ] - Epoch 78/100 - time: 22.20 - train_loss: -2.7246 - val_loss: -2.6650\n",
      "\n",
      "[ INFO : 2018-10-02 15:54:17,412 ] - Epoch 00079: val_loss did not improve from -2.72127\n",
      "[ INFO : 2018-10-02 15:54:17,413 ] - Epoch 79/100 - time: 22.20 - train_loss: -2.7282 - val_loss: -2.6334\n",
      "\n",
      "[ INFO : 2018-10-02 15:54:39,624 ] - Epoch 00080: val_loss did not improve from -2.72127\n",
      "[ INFO : 2018-10-02 15:54:39,625 ] - Epoch 80/100 - time: 22.21 - train_loss: -2.7318 - val_loss: -2.6003\n",
      "\n",
      "[ INFO : 2018-10-02 15:55:01,844 ] - Epoch 00081: val_loss improved from -2.72127 to -2.73324, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:55:05,638 ] - Epoch 81/100 - time: 26.01 - train_loss: -2.7353 - val_loss: -2.7332\n",
      "\n",
      "[ INFO : 2018-10-02 15:55:27,874 ] - Epoch 00082: val_loss did not improve from -2.73324\n",
      "[ INFO : 2018-10-02 15:55:27,876 ] - Epoch 82/100 - time: 22.23 - train_loss: -2.7388 - val_loss: -2.6238\n",
      "\n",
      "[ INFO : 2018-10-02 15:55:49,994 ] - Epoch 00083: val_loss did not improve from -2.73324\n",
      "[ INFO : 2018-10-02 15:55:49,995 ] - Epoch 83/100 - time: 22.12 - train_loss: -2.7423 - val_loss: -2.6794\n",
      "\n",
      "[ INFO : 2018-10-02 15:56:12,224 ] - Epoch 00084: val_loss did not improve from -2.73324\n",
      "[ INFO : 2018-10-02 15:56:12,225 ] - Epoch 84/100 - time: 22.23 - train_loss: -2.7454 - val_loss: -2.6795\n",
      "\n",
      "[ INFO : 2018-10-02 15:56:34,427 ] - Epoch 00085: val_loss improved from -2.73324 to -2.73875, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 15:56:40,178 ] - Epoch 85/100 - time: 27.95 - train_loss: -2.7488 - val_loss: -2.7387\n",
      "\n",
      "[ INFO : 2018-10-02 15:57:02,348 ] - Epoch 00086: val_loss did not improve from -2.73875\n",
      "[ INFO : 2018-10-02 15:57:02,348 ] - Epoch 86/100 - time: 22.17 - train_loss: -2.7521 - val_loss: -2.7268\n",
      "\n",
      "[ INFO : 2018-10-02 15:57:24,473 ] - Epoch 00087: val_loss did not improve from -2.73875\n",
      "[ INFO : 2018-10-02 15:57:24,475 ] - Epoch 87/100 - time: 22.13 - train_loss: -2.7553 - val_loss: -2.7241\n",
      "\n",
      "[ INFO : 2018-10-02 15:57:46,718 ] - Epoch 00088: val_loss did not improve from -2.73875\n",
      "[ INFO : 2018-10-02 15:57:46,719 ] - Epoch 88/100 - time: 22.24 - train_loss: -2.7586 - val_loss: -2.7220\n",
      "\n",
      "[ INFO : 2018-10-02 15:58:08,838 ] - Epoch 00089: val_loss did not improve from -2.73875\n",
      "[ INFO : 2018-10-02 15:58:08,839 ] - Epoch 89/100 - time: 22.12 - train_loss: -2.7615 - val_loss: -2.6663\n",
      "\n",
      "[ INFO : 2018-10-02 15:58:30,994 ] - Epoch 00090: val_loss did not improve from -2.73875\n",
      "[ INFO : 2018-10-02 15:58:30,995 ] - Epoch 90/100 - time: 22.16 - train_loss: -2.7645 - val_loss: -2.7259\n",
      "\n",
      "[ INFO : 2018-10-02 15:58:53,224 ] - Epoch 00091: val_loss did not improve from -2.73875\n",
      "[ INFO : 2018-10-02 15:58:53,225 ] - Epoch 91/100 - time: 22.23 - train_loss: -2.7675 - val_loss: -2.6963\n",
      "\n",
      "[ INFO : 2018-10-02 15:59:15,434 ] - Epoch 00092: val_loss did not improve from -2.73875\n",
      "[ INFO : 2018-10-02 15:59:15,435 ] - Epoch 92/100 - time: 22.21 - train_loss: -2.7705 - val_loss: -2.7251\n",
      "\n",
      "[ INFO : 2018-10-02 15:59:37,552 ] - Epoch 00093: val_loss did not improve from -2.73875\n",
      "[ INFO : 2018-10-02 15:59:37,553 ] - Epoch 93/100 - time: 22.12 - train_loss: -2.7733 - val_loss: -2.6476\n",
      "\n",
      "[ INFO : 2018-10-02 15:59:59,782 ] - Epoch 00094: val_loss did not improve from -2.73875\n",
      "[ INFO : 2018-10-02 15:59:59,783 ] - Epoch 94/100 - time: 22.23 - train_loss: -2.7761 - val_loss: -2.7321\n",
      "\n",
      "[ INFO : 2018-10-02 16:00:22,008 ] - Epoch 00095: val_loss did not improve from -2.73875\n",
      "[ INFO : 2018-10-02 16:00:22,009 ] - Epoch 95/100 - time: 22.23 - train_loss: -2.7787 - val_loss: -2.7180\n",
      "\n",
      "[ INFO : 2018-10-02 16:00:44,247 ] - Epoch 00096: val_loss did not improve from -2.73875\n",
      "[ INFO : 2018-10-02 16:00:44,248 ] - Epoch 96/100 - time: 22.24 - train_loss: -2.7815 - val_loss: -2.6185\n",
      "\n",
      "[ INFO : 2018-10-02 16:01:06,495 ] - Epoch 00097: val_loss improved from -2.73875 to -2.74240, saving model to checkpoint.model\n",
      "[ INFO : 2018-10-02 16:01:14,189 ] - Epoch 97/100 - time: 29.94 - train_loss: -2.7842 - val_loss: -2.7424\n",
      "\n",
      "[ INFO : 2018-10-02 16:01:36,430 ] - Epoch 00098: val_loss did not improve from -2.74240\n",
      "[ INFO : 2018-10-02 16:01:36,431 ] - Epoch 98/100 - time: 22.24 - train_loss: -2.7869 - val_loss: -2.7098\n",
      "\n",
      "[ INFO : 2018-10-02 16:01:58,667 ] - Epoch 00099: val_loss did not improve from -2.74240\n",
      "[ INFO : 2018-10-02 16:01:58,668 ] - Epoch 99/100 - time: 22.24 - train_loss: -2.7895 - val_loss: -2.5610\n",
      "\n",
      "[ INFO : 2018-10-02 16:02:20,861 ] - Epoch 00100: val_loss did not improve from -2.74240\n",
      "[ INFO : 2018-10-02 16:02:20,862 ] - Epoch 100/100 - time: 22.19 - train_loss: -2.7920 - val_loss: -2.7368\n",
      "\n",
      "[ INFO : 2018-10-02 16:02:23,027 ] - loss on validation data: -2.74240\n",
      "[ INFO : 2018-10-02 16:02:25,170 ] - loss on test data: -2.73272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CCA started!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Building, training, and producing the new features by DCCA\n",
    "model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1,\n",
    "                input_shape2, outdim_size, use_all_singular_values, reg_par, device=device).double()\n",
    "solver = Solver(model, epoch_num, batch_size, learning_rate, reg_par, device=device)\n",
    "train1, train2 = data1[0][0], data2[0][0]\n",
    "val1, val2 = data1[1][0], data2[1][0]\n",
    "test1, test2 = data1[2][0], data2[2][0]\n",
    "\n",
    "solver.fit(train1, train2, val1, val2, test1, test2)\n",
    "\n",
    "set_size = [0, train1.size(0), train1.size(0) + val1.size(0), train1.size(0) + val1.size(0) + test1.size(0)]\n",
    "loss, outputs = solver.test(torch.cat([train1, val1, test1], dim=0), torch.cat([train2, val2, test2], dim=0), outdim_size, apply_linear_cca)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVM...\n",
      "Accuracy on view 1 (validation data) is: 97.09\n",
      "Accuracy on view 1 (test data) is: 96.82\n"
     ]
    }
   ],
   "source": [
    "new_data = []\n",
    "# print(outputs)\n",
    "for idx in range(3):\n",
    "    new_data.append([outputs[0][set_size[idx]:set_size[idx + 1], :], outputs[1][set_size[idx]:set_size[idx + 1], :], data1[idx][1]])\n",
    "# Training and testing of SVM with linear kernel on the view 1 with new features\n",
    "[test_acc, valid_acc] = svm_classify(new_data, C=0.01)\n",
    "print(\"Accuracy on view 1 (validation data) is:\", valid_acc * 100.0)\n",
    "print(\"Accuracy on view 1 (test data) is:\", test_acc*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving new features ...\n"
     ]
    }
   ],
   "source": [
    "# Saving new features in a gzip pickled file specified by save_to\n",
    "print('saving new features ...')\n",
    "f1 = gzip.open(save_to, 'wb')\n",
    "thepickle.dump(new_data, f1)\n",
    "f1.close()\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fe6a6523ba0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.load('checkpoint.model')\n",
    "solver.model.load_state_dict(d)\n",
    "solver.model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch1.0]",
   "language": "python",
   "name": "conda-env-torch1.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
